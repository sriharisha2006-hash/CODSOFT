ğŸ“Š Customer Churn Prediction
CODSOFT Internship â€“ Task 2

ğŸ“Œ Project Overview
This project aims to predict whether a customer will churn (leave a service) based on demographic, account, and usage data.
Customer churn prediction is crucial for businesses to identify at-risk customers and take preventive action to improve retention.

We use the Telco Customer Churn Dataset and train a Random Forest Classifier to model the relationship between customer attributes and churn behavior.

ğŸ“‚ Dataset
Source: Telco Customer Churn â€“ Kaggle

Dataset Columns:

customerID â€“ Unique customer identifier

gender, SeniorCitizen, Partner, Dependents â€“ Demographic details

tenure, PhoneService, InternetService, Contract â€“ Service details

MonthlyCharges, TotalCharges â€“ Payment info

Churn â€“ Target variable (Yes/No)

ğŸ› ï¸ Technologies Used
Python

Pandas, NumPy â€“ Data manipulation

Scikit-learn â€“ Machine learning & evaluation

Matplotlib â€“ Visualization

ğŸš€ Steps Followed
Data Loading & Exploration

Read CSV file, check dataset shape & missing values.

Data Preprocessing

Convert TotalCharges to numeric and handle missing values.

Encode categorical variables using Label Encoding.

Scale numerical features with StandardScaler.

Model Training

Train a Random Forest Classifier with default parameters.

Evaluation

Accuracy score

Precision, Recall, and F1-score

Confusion Matrix

Feature Importance plot

Custom Predictions

Predict churn for sample customer data.

ğŸ“Š Results
Accuracy: ~79.8%

Class 0 (No Churn): High recall (0.91) â†’ correctly identifies most non-churn customers.

Class 1 (Churn): Lower recall (0.48) â†’ could be improved with balancing techniques.

Most important features: TotalCharges, MonthlyCharges, tenure, Contract.

ğŸ“ˆ Future Improvements
Use class_weight='balanced' in Random Forest to handle imbalance.

Apply oversampling (SMOTE) to improve churn recall.

Try Gradient Boosting models like XGBoost or LightGBM.

Feature engineering (interaction features, tenure grouping).
